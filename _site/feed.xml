<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-06-08T14:42:34-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Esther Ling</title><subtitle>Research and projects website</subtitle><entry><title type="html">Visual SLAM and Deep Learning in Complementary Forms</title><link href="http://localhost:4000/vision/2019/03/14/slam-deeplearning.html" rel="alternate" type="text/html" title="Visual SLAM and Deep Learning in Complementary Forms" /><published>2019-03-14T00:00:00-04:00</published><updated>2019-03-14T00:00:00-04:00</updated><id>http://localhost:4000/vision/2019/03/14/slam-deeplearning</id><content type="html" xml:base="http://localhost:4000/vision/2019/03/14/slam-deeplearning.html">&lt;p&gt;&lt;em&gt;By Esther Ling&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Given a robot (or a camera), determining the location of an object in a scene relative to the position of the camera in real-world measurements is a fairly challenging problem. It can be thought of as 3D localization or equivalently as 3D reconstruction coupled with an object detector. This problem is typically encountered where vision through a camera is imposed as a constraint. Some examples are: mobile robots that collect trolleys at supermarkets, pick-and-place robots at a warehouse and realistic object overlay in a phone augmented reality (AR) app.&lt;/p&gt;

&lt;p&gt;A framework for attacking this problem would be to combine an object detection module (e.g. a pre-trained convolutional neural network) and geometrical computer vision theory such as single-view metrology or multiple-view geometry. In the single-view case, one could search for vanishing points, find collinear points and apply the cross-ratio, while in the multiple-view geometry case (focus of this post), one would search for point correspondences and do the reconstruction, culminating in the structure from motion (SfM) / visual odometry pipeline.&lt;/p&gt;

&lt;p&gt;However, as researchers have studied the combined problem of object detection and visual odometry / SLAM, new ideas have emerged: what if the two could be used in tandem not only to solve the larger 3D localization problem, but &lt;em&gt;also to improve the results of each module&lt;/em&gt; in symbiotic form?&lt;/p&gt;

&lt;p&gt;Relatedly, given recent advances in deep learning not only for object detection, but also for other vision related tasks such as monocular depth estimation, other questions have been posed, for instance, can depth maps increase the accuracy of the reconstruction?&lt;/p&gt;

&lt;p&gt;Here are a few papers that explore these ideas.&lt;/p&gt;

&lt;h4 id=&quot;object-detection-to-improve-slam&quot;&gt;&lt;strong&gt;Object Detection to Improve SLAM&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1806.00557.pdf&quot;&gt;CubeSLAM: Monocular 3D Object Detection and SLAM without Prior Models&lt;/a&gt;.&lt;/em&gt; The authors for this paper propose an approach that fuses single-view 3D object detection and multiple-view SLAM. In SLAM / SfM, point correspondences are tracked between frames, and bundle-adjustment is run to minimize the re-projection or photometric error on a subset of frames. With this observation, they suggest that the tracking step could benefit not only from tracking points in the lowest-level sense, but also thinking about the points in the context of an object, i.e. points as composing higher-level features. They argue that the 3D object cuboids could provide geometric and semantic constraints that would improve bundle-adjustment. In particular, objects may contain depth cues that constrain the location of certain points.&lt;/p&gt;

&lt;p&gt;The authors use ORB-SLAM as the base SLAM model, and modify the bundle-adjustment formulation to jointly optimize for camera poses, points &lt;em&gt;and&lt;/em&gt; objects. In their experiments, they show that in a difficult dataset with large camera rotations, the cuboids help initialize the map where the original ORB-SLAM formulation fails. They also show that the geometrical constraints provided by the objects can reduce scale drift.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/8354219&quot;&gt;Detect-SLAM: Making Object Detection and SLAM Mutually Beneficial&lt;/a&gt;&lt;/em&gt;. In the SLAM / SfM pipeline, estimation of the essential matrix and 3D reconstruction rely on accurate point correspondence matching. One source of error for wrongly matched points is moving objects.&lt;/p&gt;

&lt;p&gt;In this paper, the authors use a convolutional neural network (single-shot detector) to detect moving objects belonging to a set of classes at key-frame rate. They assume that certain classes are more likely to be moving than others (such as people, animals and vehicles). Each feature point is assigned a probability of being non-stationary based on being in the region of detected objects, and this probability is propagated at frame-rate. Points above a certain threshold are excluded from the optimization of camera poses.&lt;/p&gt;

&lt;p&gt;The approach is tested on seven high-dynamic sequences, two low-dynamic sequences and one static sequence in the experiment. One question however is how to handle scenes where objects from the same class are present in static and dynamic forms. For example, assigning the same probability to moving cars and parked cars simply because they belong to the same “car” class may be an overly aggressive removal approach. The overall idea is interesting nevertheless.&lt;/p&gt;

&lt;h4 id=&quot;slam-to-improve-object-detection&quot;&gt;&lt;strong&gt;SLAM to Improve Object Detection&lt;/strong&gt;&lt;/h4&gt;
&lt;!-- (e.g. [Faster R-CNN](https://arxiv.org/abs/1506.01497), [Fast R-CNN](https://arxiv.org/abs/1504.08083) and [Selective Search](https://ivi.fnwi.uva.nl/isis/publications/bibtexbrowser.php?key=UijlingsIJCV2013&amp;bib=all.bib)) --&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.01732.pdf&quot;&gt;Monocular SLAM Supported Object Recognition&lt;/a&gt;&lt;/em&gt;. A challenge in object detection is in having good object proposals. This paper points out that mobile cameras have the advantage of observing the same object from multiple views, and hypothesize that the semi-dense representations through SLAM (such as ORB-SLAM and LSD-SLAM) may improve object proposals. In their approach, they use ORB-SLAM’s reconstructed map to infer object locations, and aggregate object predictions across multiple views.&lt;/p&gt;

&lt;h4 id=&quot;depth-prediction-to-complement-slam&quot;&gt;&lt;strong&gt;Depth Prediction to Complement SLAM&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.03489.pdf&quot;&gt;CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction&lt;/a&gt;&lt;/em&gt;. Recently, there have been studies on deep learning to infer depth from a single image. This paper postulates that such depth maps could complement monocular SLAM in several ways. For instance, depth maps (1) can be a point of reference under pure rotational motions, (2) have been shown to perform well in texture-less regions, thus making the tracking step in SLAM more robust under these conditions, and (3) can assist with recovering the absolute scale of monocular SLAM.&lt;/p&gt;

&lt;p&gt;For (3), the authors observe that one challenge is that if the depth prediction network has been trained on a set of images from a camera with different intrinsic parameters to the one used in SLAM, then the resulting scale of the 3D reconstruction will be inaccurate. They propose to weight the depth map produced by the CNN using the ratio of the focal lengths of the two cameras.&lt;/p&gt;

&lt;p&gt;While depth map prediction for recovering absolute scale is an interesting idea, reliance on an actual sensor such as an inertial-measurement unit (IMU) or GPS may be a more robust solution.&lt;/p&gt;

&lt;h4 id=&quot;conclusion&quot;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Modules that were previously in isolation may work better if the right ones are integrated together. With separate thrusts of research on deep learning and geometrical computer vision, I think that in the coming years, finding the right components to be fused together will be one source of breakthroughs in the field.&lt;/p&gt;

&lt;div id=&quot;disqus_thread&quot;&gt;&lt;/div&gt;
&lt;script&gt;
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

// var disqus_config = function () {
// this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
// this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
// };

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://lefthandwriter.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;https://disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;script id=&quot;dsq-count-scr&quot; src=&quot;//lefthandwriter.disqus.com/count.js&quot; async=&quot;&quot;&gt;&lt;/script&gt;</content><author><name></name></author><summary type="html">By Esther Ling</summary></entry><entry><title type="html">Vanishing Points in Homogeneous Coordinates</title><link href="http://localhost:4000/vision/2019/02/06/Vanishing-Points.html" rel="alternate" type="text/html" title="Vanishing Points in Homogeneous Coordinates" /><published>2019-02-06T00:00:00-05:00</published><updated>2019-02-06T00:00:00-05:00</updated><id>http://localhost:4000/vision/2019/02/06/Vanishing-Points</id><content type="html" xml:base="http://localhost:4000/vision/2019/02/06/Vanishing-Points.html">&lt;p&gt;&lt;em&gt;By Esther Ling&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;introduction&quot;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h4&gt;

&lt;!-- &lt;motivation&gt; --&gt;

&lt;!-- &lt;picture&gt; --&gt;

&lt;p&gt;We know that train tracks form parallel lines. However, in a thought experiment, if we were to stand on the tracks and observe the two outer rails, they would appear to meet as our glance approaches the horizon. Due to perspective projection, these parallel lines converge at a point called the vanishing point, or, the point at infinity [1]. In this post, I explore the use of homogeneous coordinates for reasoning about the intersection of parallel lines.&lt;/p&gt;

&lt;h4 id=&quot;homogeneous-coordinates&quot;&gt;&lt;strong&gt;Homogeneous Coordinates&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Homogeneous coordinates is a coordinate system used in projective geometry. Contrast this with the Cartesian coordinate system for Euclidean geometry. In computer vision, where we deal with projections from our 3D world to the 2D image plane, it is useful to be able to operate in either coordinate system. One way to think about homogeneous coordinates is that they are used to express points from &lt;script type=&quot;math/tex&quot;&gt;\mathbb{R}^d&lt;/script&gt; in &lt;script type=&quot;math/tex&quot;&gt;\mathbb{R}^{d+1}&lt;/script&gt; space, by augmenting a 1 for the added dimension.&lt;/p&gt;

&lt;h4 id=&quot;points&quot;&gt;&lt;strong&gt;Points&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;A point &lt;script type=&quot;math/tex&quot;&gt;p \in \mathbb{R}^2&lt;/script&gt; in the image plane can be thought of as a ray in 3D space.&lt;/p&gt;

&lt;!-- &lt;picture&gt; --&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/posts/vanishing_points/point.png&quot; alt=&quot;Schema&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When a 3D world point &lt;script type=&quot;math/tex&quot;&gt;P \in \mathbb{R}^3&lt;/script&gt; is projected onto the image plane, the depth information is lost. Consequently, when we want to figure out which world point caused &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;, we only know the answer up to scale. In other words, each point &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; is mapped not to a single point &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt;, but an equivalence class of points.&lt;/p&gt;

&lt;p&gt;So, every point on the image plane can be thought of as a ray in 3D space. Is there a way of representing a point in the image plane, such that it captures the notion of “3D-ness” (i.e. the ray from which it originates)? Using homogeneous coordinates! - we express &lt;script type=&quot;math/tex&quot;&gt;p \in \mathbb{R}^2&lt;/script&gt; as &lt;script type=&quot;math/tex&quot;&gt;\tilde{p} \in \mathbb{R}^{2+1} = \mathbb{R}^{3}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Define our image point in homogeneous coordinates as:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\tilde{p} = [x, y, 1]^T&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;To convert back to Euclidean coordinates from homogeneous coordinates, we divide the first and second element by the third element:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;p = [x/z, y/z]^T&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Looking at the diagram again, notice that any point along the ray is equivalent to another point on that ray, which this representation captures:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{p} = [\alpha x, \alpha y, \alpha]^T,&lt;/script&gt;

&lt;p&gt;for some &lt;script type=&quot;math/tex&quot;&gt;\alpha \in \mathbb{R}&lt;/script&gt; to represent the possible depths where the 3D point lies.&lt;/p&gt;

&lt;p&gt;Notice that we can also express the ray in 3D space as a line: &lt;script type=&quot;math/tex&quot;&gt;r = [a, b, c]^T&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;With this representation, we are able to express points in the image and their rays in the same coordinate system.&lt;/p&gt;

&lt;h4 id=&quot;lines&quot;&gt;&lt;strong&gt;Lines&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;How about lines in an image?&lt;/p&gt;

&lt;!-- &lt;picture&gt; --&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/posts/vanishing_points/line.png&quot; alt=&quot;Schema&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can think of a line as having two end points, with infinitely many points in between them. Each of these points have a ray associated with them. So, a line in an image forms a plane in 3D space.&lt;/p&gt;

&lt;p&gt;We can parametrize a line in the image using homogeneous coordinates by &lt;script type=&quot;math/tex&quot;&gt;l = [a, b, c]^T&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;ax + by + cz = 0&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;To relate this system with how we might be more familiar with parameterizing lines (i.e. a slope and an intercept):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;ax + by + cz = 0&lt;/script&gt;

&lt;p&gt;Sub-in point &lt;script type=&quot;math/tex&quot;&gt;\tilde{p} = [x, y, 1]^T&lt;/script&gt; into the equation above, to get:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;ax + by + c = 0&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Re-arranging, we get:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = -\frac{a}{b} x - \frac{c}{b}&lt;/script&gt;

&lt;p&gt;where the slope = &lt;script type=&quot;math/tex&quot;&gt;-\frac{a}{b}&lt;/script&gt; and the intercept = &lt;script type=&quot;math/tex&quot;&gt;-\frac{c}{b}&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;intersection-of-lines&quot;&gt;&lt;strong&gt;Intersection of Lines&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;Generally, two lines &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt; intersect at a point &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;With the slope and intercept line parameterization, we can find this point by equating the equations for &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_1: y = m_1x + c_1&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_2: y = m_2x + c_2&lt;/script&gt;

&lt;p&gt;to find &lt;script type=&quot;math/tex&quot;&gt;k = [x, y]^T&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;However, we run into a problem when the slopes are equivalent, i.e. &lt;script type=&quot;math/tex&quot;&gt;m_1 = m_2&lt;/script&gt;. In other words, the slope and intercept line parameterization doesn’t really help us when thinking about the intersection of two parallel lines.&lt;/p&gt;

&lt;p&gt;Let’s see if homogeneous coordinates are more helpful.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Theorem&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;The intersection point &lt;script type=&quot;math/tex&quot;&gt;\tilde{k}&lt;/script&gt; between two lines &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt; can be found by &lt;script type=&quot;math/tex&quot;&gt;\tilde{k} = l_1 \times l_2&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;\times&lt;/script&gt; denotes the vector cross-product.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;If &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt; intersect, then the intersection point &lt;script type=&quot;math/tex&quot;&gt;\tilde{k}&lt;/script&gt; falls on both lines. Then, we just need to show that &lt;script type=&quot;math/tex&quot;&gt;l_1^T\tilde{k}=0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2^T\tilde{k}=0&lt;/script&gt; are true. From the statement &lt;script type=&quot;math/tex&quot;&gt;\tilde{k} = l_1 \times l_2&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\tilde{k}&lt;/script&gt; is a vector orthogonal to the space spanned by &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt;. Hence, &lt;script type=&quot;math/tex&quot;&gt;l_1^T\tilde{k}=0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2^T\tilde{k}=0&lt;/script&gt; are true. &lt;em&gt;q.e.d.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Suppose &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt; are parallel. Then, they have the same slope:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_1: [a, b, c_1]^T&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_2: [a, b, c_2]^T&lt;/script&gt;

&lt;p&gt;Using the cross-product to find their intersection:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{k} = \left[ \begin{array}{c}
		b(c_2 - c_1) \\
		-a(c_2 - c_1) \\
		0 \end{array} \right]&lt;/script&gt;

&lt;p&gt;Now, when we convert &lt;script type=&quot;math/tex&quot;&gt;\tilde{k}&lt;/script&gt; back to its Euclidean form, we get:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;k = \left[ \begin{array}{c}
		\frac{b(c_2 - c_1)}{0} \\
		-\frac{a(c_2 - c_1)}{0} \end{array} \right] = k_\infty&lt;/script&gt;

&lt;p&gt;which is a division by zero, and hence a point at infinity!&lt;/p&gt;

&lt;h4 id=&quot;parallel-lines-with-equal-slope-meet&quot;&gt;&lt;strong&gt;Parallel Lines with Equal Slope Meet&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;We can extend the analysis to show that all lines parallel to &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt; intersect at the same point &lt;script type=&quot;math/tex&quot;&gt;k_\infty&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;First, we can simplify &lt;script type=&quot;math/tex&quot;&gt;\tilde{k}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{k} = \alpha \left[ \begin{array}{c}
		b \\
	   -a \\
		0 \end{array} \right]&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\alpha = c_2 - c_1&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;l_p&lt;/script&gt; represent any line parallel to &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt;, i.e&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;l_p = [a, b, c_p]^T&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;What remains to show is &lt;script type=&quot;math/tex&quot;&gt;l_p^T k_\infty = 0&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Expanding &lt;script type=&quot;math/tex&quot;&gt;l_p^T k_\infty&lt;/script&gt;:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
l_p^T k_\infty = \left[ \begin{array}{ccc}
		a &amp; b &amp; c \end{array} \right]\left[ \begin{array}{c}
		b \\
	   -a \\
		0 \end{array} \right] = 0 %]]&gt;&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Hence, any line parallel to &lt;script type=&quot;math/tex&quot;&gt;l_1&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;l_2&lt;/script&gt; intersect at the same point &lt;script type=&quot;math/tex&quot;&gt;k_\infty&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;references&quot;&gt;&lt;strong&gt;References&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;[1] I came across this illustration in the book “How not to be wrong - the power of mathematical thinking” by Jordan Ellenberg.&lt;/p&gt;

&lt;p&gt;[2] I credit much of the math in this piece to &lt;a href=&quot;https://web.stanford.edu/class/cs231a/course_notes/02-single-view-metrology.pdf&quot;&gt;these course notes&lt;/a&gt;.&lt;/p&gt;

&lt;div id=&quot;disqus_thread&quot;&gt;&lt;/div&gt;
&lt;script&gt;
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

// var disqus_config = function () {
// this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
// this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
// };

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://lefthandwriter.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;https://disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;script id=&quot;dsq-count-scr&quot; src=&quot;//lefthandwriter.disqus.com/count.js&quot; async=&quot;&quot;&gt;&lt;/script&gt;</content><author><name></name></author><summary type="html">By Esther Ling</summary></entry><entry><title type="html">Using the ChargePoint API with Python</title><link href="http://localhost:4000/software/2018/06/22/Designing-EV-Database.html" rel="alternate" type="text/html" title="Using the ChargePoint API with Python" /><published>2018-06-22T00:00:00-04:00</published><updated>2018-06-22T00:00:00-04:00</updated><id>http://localhost:4000/software/2018/06/22/Designing-EV-Database</id><content type="html" xml:base="http://localhost:4000/software/2018/06/22/Designing-EV-Database.html">&lt;p&gt;Here’s a short post on my recent experience getting data from the ChargePoint API using Zeep in Python. The end-goal was to then design an SQL database based on the type of data returned by the API call, for an EV project I’m working on.&lt;/p&gt;

&lt;h4 id=&quot;figuring-out-the-api&quot;&gt;Figuring out the API&lt;/h4&gt;

&lt;p&gt;First up was to figure out the API. The ChargePoint API is a SOAP API, which was new to me as I’d only worked with REST APIs up to this point. I did a quick lookup to find a software package that I could work with and settled with &lt;a href=&quot;https://github.com/mvantellingen/python-zeep&quot;&gt;Zeep&lt;/a&gt;, a Python package. I found this &lt;a href=&quot;https://medium.com/@adriennedomingus/using-zeep-to-make-soap-requests-in-python-c575ea0ee954&quot;&gt;tutorial&lt;/a&gt; particularly helpful in getting started with Zeep.&lt;/p&gt;

&lt;p&gt;Next was figuring out the endpoint. The ChargePoint manual that’s available online doesn’t explain this explicitly, but I managed to find the WSDL &lt;a href=&quot;http://volttron.readthedocs.io/en/releases-4.1/specifications/chargepoint_driver.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;With this sorted, I then looked at the &lt;a href=&quot;https://na.chargepoint.com/UI/downloads/en/ChargePoint_Web_Services_API_Guide_Ver4.1_Rev4.pdf&quot;&gt;ChargePoint manual&lt;/a&gt; to see the types of methods available for an API call, and the information returned. My goal was to create a local database that stored the stations available in the network and the list of historical charging sessions. The two methods I needed were in Chapter 9 on Usage Analysis, and Chapter 10 on Station Management. Basically, the &lt;code class=&quot;highlighter-rouge&quot;&gt;getChargingSessionData&lt;/code&gt; method returns parameters such as the sessionID, userID, stationID, stationName, startTime, endTime, Energy, and Address, while the &lt;code class=&quot;highlighter-rouge&quot;&gt;getStations&lt;/code&gt; method returns the station information.&lt;/p&gt;

&lt;h4 id=&quot;designing-the-database&quot;&gt;Designing the database&lt;/h4&gt;

&lt;p&gt;With the response parameters from the API methods in hand, I laid out all the information available from an API call, and then designed the SQL database on hand. Basically, I created one table for each of the following entities: station, port, pricing, user, session, and payment. Each of these tables has a primary key, i.e. the station table has the stationID as its primary key, the port table has the portID as its primary key, and so on. I also included foreign keys for cross-referencing between tables, such as the stationID in the session table as a foreign key referencing the stationID in the station table.&lt;/p&gt;

&lt;p&gt;Here’s a diagram of the database schema:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/databaseSchema.png&quot; alt=&quot;Schema&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;the-code&quot;&gt;The code&lt;/h4&gt;

&lt;p&gt;I wrote code to pull data from the API and populate the database using SQLite in Python. This was a process of creating the tables -&amp;gt; pull data from the API -&amp;gt; populate the rows in the appropriate table.&lt;/p&gt;

&lt;p&gt;The code is written in such a way so that the user would enter a range from which to query data from, specified by a startTime and endTime, in Python datetime format. Since the ChargePoint API only allows a maximum of 100 sessions returned per API call, I set it so that it would make one call per day in the range, under the assumption that not more than 100 charging sessions are encountered per day. This works if your organization is relatively small like the one we have at Tech, but you’d need to modify the code otherwise.&lt;/p&gt;

&lt;p&gt;I’ve posted the code on Github &lt;a href=&quot;https://github.com/lefthandwriter/ChargePointAPI&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div id=&quot;disqus_thread&quot;&gt;&lt;/div&gt;
&lt;script&gt;
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

// var disqus_config = function () {
// this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
// this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
// };

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://lefthandwriter.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
&lt;/script&gt;

&lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;https://disqus.com/?ref_noscript&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;

&lt;script id=&quot;dsq-count-scr&quot; src=&quot;//lefthandwriter.disqus.com/count.js&quot; async=&quot;&quot;&gt;&lt;/script&gt;</content><author><name></name></author><summary type="html">Here’s a short post on my recent experience getting data from the ChargePoint API using Zeep in Python. The end-goal was to then design an SQL database based on the type of data returned by the API call, for an EV project I’m working on.</summary></entry></feed>